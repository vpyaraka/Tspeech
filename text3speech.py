# -*- coding: utf-8 -*-
"""Text3Speech.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mr6CohagF-oRnEpW1j230Ot6X91E_P4e
"""

import streamlit as st
import openai

# ----------------------
# Initialize OpenAI client
# ----------------------
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

st.title("Your ChatBot Name ðŸ¤–ðŸŽ™ï¸")

# ----------------------
# Session State for Chat History
# ----------------------
if "messages" not in st.session_state:
    st.session_state.messages = []

# ----------------------
# Mock Emotion Detector (replace with real ML model later)
# ----------------------
def detect_emotion(text: str) -> str:
    if any(word in text.lower() for word in ["happy", "great", "awesome", "love"]):
        return "happy"
    elif any(word in text.lower() for word in ["sad", "tired", "exhausted", "down"]):
        return "sad"
    elif any(word in text.lower() for word in ["angry", "mad", "furious", "annoyed"]):
        return "angry"
    else:
        return "neutral"

# ----------------------
# Mock Audio Generator (replace with real TTS service)
# ----------------------
def generate_audio(text: str, emotion: str) -> str:
    # Here you'd call a TTS API like gTTS, ElevenLabs, etc.
    # For now, just return a placeholder file path
    return f"audio/{emotion}_voice_sample.mp3"

# ----------------------
# GPT Response with Emotion-Aware Tone
# ----------------------
def get_response(user_emotion: str):
    tone_map = {
        "neutral": "Respond in a balanced, professional, and clear tone.",
        "happy": "Respond in a cheerful, friendly, and encouraging tone.",
        "sad": "Respond in a gentle, empathetic, and supportive tone.",
        "angry": "Respond in a calm, understanding, and de-escalating tone."
    }

    system_instruction = f"You are an assistant. {tone_map.get(user_emotion, tone_map['neutral'])}"

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "system", "content": system_instruction}] +
                 [{"role": m["role"], "content": m["content"]} for m in st.session_state.messages if m["role"] != "assistant_audio"]
    )
    return response.choices[0].message.content

# ----------------------
# Display Chat History
# ----------------------
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(f"**{msg['emotion'].capitalize()} tone:** {msg['content']}")
        if "audio" in msg:
            st.audio(msg["audio"])

# ----------------------
# User Input
# ----------------------
if user_input := st.chat_input("Say something..."):
    # Detect emotion
    user_emotion = detect_emotion(user_input)

    # Save user message
    st.session_state.messages.append({
        "role": "user",
        "content": user_input,
        "emotion": user_emotion
    })

    # Display user message
    with st.chat_message("user"):
        st.markdown(f"**{user_emotion.capitalize()} tone:** {user_input}")

    # Generate assistant response
    assistant_reply = get_response(user_emotion)
    assistant_emotion = user_emotion
    audio_file_reply = generate_audio(assistant_reply, emotion=assistant_emotion)

    # Save assistant message
    st.session_state.messages.append({
        "role": "assistant",
        "content": assistant_reply,
        "emotion": assistant_emotion,
        "audio": audio_file_reply
    })

    # Display assistant message
    with st.chat_message("assistant"):
        st.markdown(f"**{assistant_emotion.capitalize()} tone:** {assistant_reply}")
        st.audio(audio_file_reply)